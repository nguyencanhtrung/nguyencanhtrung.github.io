I"ï5<h2 id="1-gi·ªõi-thi·ªáu">1. Gi·ªõi thi·ªáu</h2>

<p>N·ªëi ti·∫øp ph·∫ßn 1, ph·∫ßn n√†y s·∫Ω m√¥ t·∫£ chi ti·∫øt v·ªÅ vi·ªác c√†i ƒë·∫∑t m√°y ·∫£o KVM. Ph·∫ßn h∆∞·ªõng d·∫´n n√†y s·∫Ω ƒë∆∞·ª£c m√¥ t·∫£ b·∫±ng ti·∫øng Anh.</p>

<h2 id="2-prerequisites">2. Prerequisites</h2>

<p>Before getting started, ensure that you meet the following prerequisites:</p>

<ol>
  <li>
    <p><strong>Linux System</strong>: Ubuntu 20.04 - kernel v5.15.</p>
  </li>
  <li>
    <p><strong>Bios</strong>: Make sure Intel Virtualization Technology (Intel VT) and Intel ¬Æ VT-d must be enabled from server BIOS</p>
  </li>
  <li>
    <p><strong>CPU Support</strong>: Check if your CPU supports virtualization and IOMMU (Input-Output Memory Management Unit) by running:</p>
  </li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>egrep -c '(vmx|svm)' /proc/cpuinfo
</code></pre></div></div>
<p>If the command returns a value of 0, your processor is not capable of running KVM. On the other hand, any other number means you can proceed with the installation.</p>

<p>You are now ready to start installing KVM.</p>

<h2 id="3-kvm-installation">3. KVM Installation</h2>

<h3 id="a-install-kvm-and-assorted-tools">a. Install KVM and assorted tools</h3>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt <span class="nb">install </span>qemu-kvm libvirt-clients libvirt-daemon-system virtinst bridge-utils cpu-checker virt-viewer virt-manager qemu-system
</code></pre></div></div>

<h3 id="b-check-whether-your-system-can-use-kvm-acceleration">b. Check whether your system can use KVM acceleration</h3>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>kvm-ok
</code></pre></div></div>

<p>The output should look like this:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tesla@tesla:~/kvm<span class="nv">$ </span>kvm-ok
INFO: /dev/kvm exists
KVM acceleration can be used
</code></pre></div></div>

<p>Then run the virt-host-validate utility to run a whole set of checks against your virtualization ability and KVM readiness.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>virt-host-validate
QEMU: Checking <span class="k">for </span>hardware virtualization                                 : PASS
QEMU: Checking <span class="k">if </span>device /dev/kvm exists                                   : PASS
QEMU: Checking <span class="k">if </span>device /dev/kvm is accessible                            : PASS
QEMU: Checking <span class="k">if </span>device /dev/vhost-net exists                             : PASS
QEMU: Checking <span class="k">if </span>device /dev/net/tun exists                               : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'memory'</span> controller support                      : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'memory'</span> controller mount-point                  : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'cpu'</span> controller support                         : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'cpu'</span> controller mount-point                     : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'cpuacct'</span> controller support                     : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'cpuacct'</span> controller mount-point                 : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'cpuset'</span> controller support                      : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'cpuset'</span> controller mount-point                  : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'devices'</span> controller support                     : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'devices'</span> controller mount-point                 : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'blkio'</span> controller support                       : PASS
QEMU: Checking <span class="k">for </span>cgroup <span class="s1">'blkio'</span> controller mount-point                   : PASS
QEMU: Checking <span class="k">for </span>device assignment IOMMU support                         : PASS
 LXC: Checking <span class="k">for </span>Linux <span class="o">&gt;=</span> 2.6.26                                         : PASS
 LXC: Checking <span class="k">for </span>namespace ipc                                           : PASS
 LXC: Checking <span class="k">for </span>namespace mnt                                           : PASS
 LXC: Checking <span class="k">for </span>namespace pid                                           : PASS
 LXC: Checking <span class="k">for </span>namespace uts                                           : PASS
 LXC: Checking <span class="k">for </span>namespace net                                           : PASS
 LXC: Checking <span class="k">for </span>namespace user                                          : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'memory'</span> controller support                      : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'memory'</span> controller mount-point                  : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'cpu'</span> controller support                         : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'cpu'</span> controller mount-point                     : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'cpuacct'</span> controller support                     : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'cpuacct'</span> controller mount-point                 : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'cpuset'</span> controller support                      : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'cpuset'</span> controller mount-point                  : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'devices'</span> controller support                     : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'devices'</span> controller mount-point                 : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'blkio'</span> controller support                       : PASS
 LXC: Checking <span class="k">for </span>cgroup <span class="s1">'blkio'</span> controller mount-point                   : PASS
 LXC: Checking <span class="k">if </span>device /sys/fs/fuse/connections exists                   : PASS
</code></pre></div></div>

<h3 id="c-add-user-to-libvirt-groups">c. Add user to libvirt groups</h3>

<p>To allow the current user to manage the guest VM without sudo, we can add ourselves to all of the libvirt groups (e.g. libvirt, libvirt-qemu) and the kvm group</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>libvirt | <span class="nb">awk</span> <span class="nt">-F</span><span class="s1">':'</span> <span class="o">{</span><span class="s1">'print $1'</span><span class="o">}</span> | xargs <span class="nt">-n1</span> <span class="nb">sudo </span>adduser <span class="nv">$USER</span>

<span class="c"># add user to kvm group also</span>
<span class="nb">sudo </span>adduser <span class="nv">$USER</span> kvm

<span class="c"># relogin, then show group membership</span>
<span class="nb">exec </span>su <span class="nt">-l</span> <span class="nv">$USER</span>
<span class="nb">id</span> | <span class="nb">grep </span>libvirt
</code></pre></div></div>

<p>Group membership requires a user to log back in, so if the <code class="language-plaintext highlighter-rouge">id</code> command does not show your libvirt* group membership, logout and log back in, or try <code class="language-plaintext highlighter-rouge">exec su -l $USER</code>.</p>

<h3 id="d-qemu-connection-to-system">d. QEMU connection to system</h3>

<p>If not explicitly set, the userspace QEMU connection will be to <code class="language-plaintext highlighter-rouge">qemu:///session</code>, and not to <code class="language-plaintext highlighter-rouge">qemu:///system</code>.  This will cause you to see different domains, networks, and disk pool when executing virsh as your regular user versus sudo.</p>

<p>Modify your profile so that the environment variable below is exported to your login sessions.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use same connection and objects as sudo</span>
<span class="nb">export </span><span class="nv">LIBVIRT_DEFAULT_URI</span><span class="o">=</span>qemu:///system
</code></pre></div></div>

<h3 id="5-default-network">5. Default network</h3>

<p>By default, KVM creates a virtual switch that shows up as a host interface named <code class="language-plaintext highlighter-rouge">virbr0</code> using 192.168.122.0/24.</p>

<p>This interface should be visible from the Host using the ‚Äúip‚Äù command below.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ip addr show virbr0
3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    <span class="nb">link</span>/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">virbr0</code> operates in NAT mode, which allows the guest OS to communicate out, but only allowing the Host(and those VMs in its subnet) to make incoming connections.</p>

<h3 id="6-bridge-network">6. Bridge network</h3>

<p>To enable guest VMs on the same network as the Host, you should create a bridged network to your physical interface (e.g. eth0, ens4, epn1s0).</p>

<p>Read my article here for how to use NetPlan on Ubuntu to bridge your physical network interface to <code class="language-plaintext highlighter-rouge">br0</code> at the OS level.  And then use that to create a libvirt network named <code class="language-plaintext highlighter-rouge">host-bridge</code> that uses <code class="language-plaintext highlighter-rouge">br0</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># bridge to physical network</span>
<span class="nv">$ </span>virsh net-dumpxml host-bridge

&lt;network <span class="nv">connections</span><span class="o">=</span><span class="s1">'2'</span><span class="o">&gt;</span>
  &lt;name&gt;host-bridge&lt;/name&gt;
  &lt;uuid&gt;44d2c3f5-6301-4fc6-be81-5ae2be4a47d8&lt;/uuid&gt;
  &lt;forward <span class="nv">mode</span><span class="o">=</span><span class="s1">'bridge'</span>/&gt;
  &lt;bridge <span class="nv">name</span><span class="o">=</span><span class="s1">'br0'</span>/&gt;
&lt;/network&gt;
</code></pre></div></div>

<p>This <code class="language-plaintext highlighter-rouge">host-bridge</code> will be required in later articles.</p>

<p>Instruction to setup host‚Äôs OS to create <code class="language-plaintext highlighter-rouge">br0</code> <a href="https://fabianlee.org/2019/04/01/kvm-creating-a-bridged-network-with-netplan-on-ubuntu-bionic/">here</a></p>

<h3 id="7-enable-ipv4-forwarding-on-kvm-host">7. Enable IPv4 forwarding on KVM host</h3>

<p>In order to handle NAT and routed networks for KVM, enable IPv4 forwarding on this host.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># this needs to be "1"</span>
<span class="nb">cat</span> /proc/sys/net/ipv4/ip_forward
<span class="c"># if not, then add it</span>
<span class="nb">echo </span>net.ipv4.ip_forward<span class="o">=</span>1 | <span class="nb">sudo tee</span> <span class="nt">-a</span> /etc/sysctl.conf

<span class="c"># make permanent</span>
<span class="nb">sudo </span>sysctl <span class="nt">-p</span> /etc/sysctl.conf
</code></pre></div></div>

<h3 id="8-default-storage-pool">8. Default storage pool</h3>

<p>The ‚Äúdefault‚Äù storage pool for guest disks is <code class="language-plaintext highlighter-rouge">/var/lib/libvirt/images</code>.   This is fine for test purposes, but if you have another mount that you want to use for guest OS disks, then you should create a custom storage pool.</p>

<p>Below are the commands to create a ‚Äúkvmpool‚Äù on an SSD mounted at <code class="language-plaintext highlighter-rouge">/data/kvm/pool</code>.</p>

<p>```shell
$ virsh pool-list ‚Äìall
 Name                 State      Autostart 
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-
 default              active     yes</p>

<p>$ virsh pool-define-as kvmpool ‚Äìtype dir ‚Äìtarget /data/kvm/pool
Pool kvmpool defined
$ virsh pool-list ‚Äìall
$ virsh pool-start kvmpool
$ virsh pool-autostart kvmpool</p>

<p>$ virsh pool-list ‚Äìall
 Name                 State      Autostart 
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-
 default              active     yes     <br />
 kvmpool              active     yes</p>
:ET